---
phase: 00-deployment-infrastructure
plan: 05
type: execute
wave: 1
depends_on: ["00-03", "00-04"]
files_modified:
  - hooks/gsd-check-update.js
  - commands/gsd/update.md
  - tests/benchmarks/framework.js
  - tests/e2e/real-agent.test.js
  - tests/benchmarks/package.json
  - .github/workflows/ci.yml
autonomous: true

must_haves:
  truths:
    - "gsd-check-update.js queries 'get-shit-done-reflect-cc' on npm, not the upstream 'get-shit-done-cc'"
    - "commands/gsd/update.md references 'get-shit-done-reflect-cc' in all npm and npx commands"
    - "Benchmark comparison correctly identifies lower execution_time as improvement, not regression"
    - "CI pipeline runs infrastructure tests (test:infra) and install verification on every PR"
    - "Vitest E2E test timeout uses numeric syntax compatible with Vitest 4"
    - "Benchmark runner runs without ESM MODULE_TYPELESS_PACKAGE_JSON warning"
  artifacts:
    - path: "hooks/gsd-check-update.js"
      provides: "Update checker querying fork package"
      contains: "get-shit-done-reflect-cc"
    - path: "commands/gsd/update.md"
      provides: "Update command referencing fork package"
      contains: "get-shit-done-reflect-cc"
    - path: "tests/benchmarks/framework.js"
      provides: "Fixed benchmark comparison logic"
      contains: "lowerIsBetter"
    - path: "tests/benchmarks/package.json"
      provides: "ESM type declaration for benchmark modules"
      contains: "\"type\": \"module\""
    - path: ".github/workflows/ci.yml"
      provides: "CI pipeline with infra tests and install verification"
      contains: "test:infra"
  key_links:
    - from: "hooks/gsd-check-update.js"
      to: "npm registry"
      via: "npm view command"
      pattern: "npm view get-shit-done-reflect-cc"
    - from: ".github/workflows/ci.yml"
      to: "package.json scripts"
      via: "npm run test:infra"
      pattern: "npm run test:infra"
---

<objective>
Fix package name references pointing to upstream instead of fork, resolve three tech debt items from the v1 milestone audit, and harden the CI pipeline with infrastructure tests and install verification.

Purpose: The update checker and update command currently query the upstream "get-shit-done-cc" package instead of the fork "get-shit-done-reflect-cc", which means users would be told to update to the wrong package. The tech debt fixes address known issues in benchmark comparison logic, ESM module warnings, and Vitest deprecation. CI hardening ensures infrastructure tests gate PRs.
Output: Corrected package references, fixed benchmark logic, suppressed ESM warning, updated test syntax, and enhanced CI workflow.
</objective>

<execution_context>
@/Users/rookslog/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rookslog/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/v1-MILESTONE-AUDIT.md
@.planning/phases/00-deployment-infrastructure/00-03-SUMMARY.md
@.planning/phases/00-deployment-infrastructure/00-04-SUMMARY.md
@hooks/gsd-check-update.js
@commands/gsd/update.md
@tests/benchmarks/framework.js
@tests/e2e/real-agent.test.js
@.github/workflows/ci.yml
@package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix package name references from upstream to fork</name>
  <files>hooks/gsd-check-update.js, commands/gsd/update.md</files>
  <action>
Two files reference the upstream package name "get-shit-done-cc" instead of the fork "get-shit-done-reflect-cc". Fix both.

**hooks/gsd-check-update.js (line 45):**
Change:
```javascript
latest = execSync('npm view get-shit-done-cc version', { encoding: 'utf8', timeout: 10000, windowsHide: true }).trim();
```
To:
```javascript
latest = execSync('npm view get-shit-done-reflect-cc version', { encoding: 'utf8', timeout: 10000, windowsHide: true }).trim();
```

**commands/gsd/update.md:**
Replace ALL occurrences of "get-shit-done-cc" with "get-shit-done-reflect-cc". There are multiple references:
1. Line 9: `npx get-shit-done-cc` in objective description
2. Line 39: `npm view get-shit-done-cc version` in check step
3. Line 47: `npx get-shit-done-cc --global` in manual update instruction
4. Line 135: `npx get-shit-done-cc --global` in run_update step

Also update the GitHub URL reference on line 157 from `glittercowboy/get-shit-done` to `rookslog/get-shit-done-reflect` to point to the fork's changelog.

Do NOT change the VERSION file paths (these reference `~/.claude/get-shit-done/VERSION` which is the install directory, not the package name -- these are correct as-is).
  </action>
  <verify>
1. `grep -c "get-shit-done-cc" hooks/gsd-check-update.js` returns 0 (no upstream references remain)
2. `grep -c "get-shit-done-reflect-cc" hooks/gsd-check-update.js` returns 1
3. `grep -c "get-shit-done-cc" commands/gsd/update.md` returns 0
4. `grep -c "get-shit-done-reflect-cc" commands/gsd/update.md` returns 4
5. `grep "rookslog/get-shit-done-reflect" commands/gsd/update.md` shows updated GitHub URL
  </verify>
  <done>All npm/npx references point to "get-shit-done-reflect-cc". No upstream package name references remain in update-related code.</done>
</task>

<task type="auto">
  <name>Task 2: Fix three tech debt items from milestone audit</name>
  <files>tests/benchmarks/framework.js, tests/e2e/real-agent.test.js, tests/benchmarks/package.json</files>
  <action>
Fix three tech debt items identified in the v1 milestone audit.

**Fix 1: Benchmark comparison regression logic (tests/benchmarks/framework.js)**

The `compareRuns` function (lines 226-267) treats ALL metrics with "higher is better" logic. For `execution_time`, lower is better -- a faster benchmark is an improvement, not a regression.

In the `compareRuns` function, replace the metric comparison loop with direction-aware logic:

```javascript
// Metrics where lower values are better (not higher)
const lowerIsBetter = new Set(['execution_time'])

// Compare key metrics
const metricsToCompare = ['signals_captured', 'kb_entries', 'execution_time']
let improved = false
let regressed = false

for (const metric of metricsToCompare) {
  const current = result.metrics[metric]
  const baseline = base.metrics[metric]
  if (current === baseline) continue

  const isLowerBetter = lowerIsBetter.has(metric)
  const isHigher = current > baseline

  if (isHigher === !isLowerBetter) {
    // Higher is good for normal metrics, lower is good for lowerIsBetter metrics
    improved = true
  } else {
    regressed = true
  }
}
```

This replaces the existing comparison block (lines 245-256 approximately) that unconditionally treats higher as improved.

**Fix 2: Vitest E2E timeout deprecation (tests/e2e/real-agent.test.js)**

Line 98 uses the deprecated object syntax:
```javascript
}, { timeout: 120000 }) // 2 minute timeout for agent execution
```

Change to numeric third argument:
```javascript
}, 120000) // 2 minute timeout for agent execution
```

Note: `tmpdirTest` is a custom wrapper. Check its signature in `tests/helpers/tmpdir.js`. If it passes through the third arg to Vitest's `it()`, the numeric form works. If the wrapper expects an options object, keep the object form and add a comment noting the Vitest 4 migration needed. Prefer the numeric form if the wrapper supports it.

**Fix 3: ESM module warning (tests/benchmarks/package.json)**

Create a minimal `tests/benchmarks/package.json` to declare ESM module type for the benchmark directory:

```json
{
  "type": "module"
}
```

This suppresses the NODE_TYPELESS_PACKAGE_JSON warning when running `node tests/benchmarks/runner.js` without affecting the root package.json or any other code.
  </action>
  <verify>
1. `grep "lowerIsBetter" tests/benchmarks/framework.js` confirms direction-aware comparison exists
2. `grep -n "timeout: 120000" tests/e2e/real-agent.test.js` returns 0 matches (object syntax removed)
3. `cat tests/benchmarks/package.json` shows `{"type": "module"}`
4. `node tests/benchmarks/runner.js --tier quick 2>&1 | grep -c "MODULE_TYPELESS"` returns 0 (warning suppressed)
5. `npm test` passes (existing tests unbroken)
  </verify>
  <done>Benchmark comparison correctly handles execution_time as lower-is-better. Vitest timeout uses non-deprecated syntax. Benchmark runner runs without ESM warning.</done>
</task>

<task type="auto">
  <name>Task 3: Add infrastructure tests and install verification to CI</name>
  <files>.github/workflows/ci.yml</files>
  <action>
Enhance the CI workflow to run infrastructure tests and verify the install script works in an isolated environment.

**Add to .github/workflows/ci.yml** -- insert two new steps after "Run tests" and before "Run tests with coverage":

```yaml
      - name: Run infrastructure tests
        run: npm run test:infra

      - name: Verify install script
        run: |
          # Create isolated temp directory simulating fresh install
          INSTALL_DIR=$(mktemp -d)

          # Run install.js with --claude flag and HOME pointing to temp dir
          # This tests the installer works without actually modifying the real home
          HOME="$INSTALL_DIR" node bin/install.js --claude 2>&1 || true

          # Verify expected directories were created
          if [ -d "$INSTALL_DIR/.claude/commands/gsd" ]; then
            echo "Install verification: PASS - commands/gsd directory created"
          else
            echo "Install verification: FAIL - commands/gsd directory not found"
            ls -la "$INSTALL_DIR/.claude/" 2>/dev/null || echo "No .claude directory at all"
            exit 1
          fi

          if [ -d "$INSTALL_DIR/.claude/get-shit-done" ]; then
            echo "Install verification: PASS - get-shit-done directory created"
          else
            echo "Install verification: FAIL - get-shit-done directory not found"
            exit 1
          fi

          # Check VERSION file was written
          if [ -f "$INSTALL_DIR/.claude/get-shit-done/VERSION" ]; then
            VERSION=$(cat "$INSTALL_DIR/.claude/get-shit-done/VERSION")
            PKG_VERSION=$(node -p "require('./package.json').version")
            echo "Install verification: PASS - VERSION file exists ($VERSION)"
            if [ "$VERSION" = "$PKG_VERSION" ]; then
              echo "Install verification: PASS - Version matches package.json"
            else
              echo "Install verification: WARN - Version mismatch ($VERSION vs $PKG_VERSION)"
            fi
          fi

          # Cleanup
          rm -rf "$INSTALL_DIR"
          echo "Install verification: COMPLETE"
```

The install test runs bin/install.js in an isolated temp directory by overriding HOME, then verifies the expected directory structure was created. The `|| true` after install.js handles the case where the installer prompts for input (it will exit on EOF but may have already copied files).

Do NOT add the smoke test step here -- that requires Claude CLI authentication and is handled separately in plan 00-06.
  </action>
  <verify>
1. `grep "test:infra" .github/workflows/ci.yml` confirms infrastructure test step exists
2. `grep "Verify install script" .github/workflows/ci.yml` confirms install verification step exists
3. `grep "mktemp" .github/workflows/ci.yml` confirms isolated temp directory usage
4. The YAML is valid: `python3 -c "import yaml; yaml.safe_load(open('.github/workflows/ci.yml'))"` or visual inspection of indentation
  </verify>
  <done>CI workflow runs npm run test:infra (zero cost, gates PRs) and verifies bin/install.js creates correct directory structure in isolated environment.</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `grep -r "get-shit-done-cc" hooks/ commands/gsd/update.md` returns only "get-shit-done-reflect-cc" matches (no bare upstream refs)
2. `npm test` passes (no regressions from tech debt fixes)
3. `node tests/benchmarks/runner.js --tier quick` runs without ESM warning
4. CI YAML is syntactically valid
5. `npm run test:infra` passes locally
</verification>

<success_criteria>
- All package name references updated from upstream to fork
- Benchmark comparison handles lower-is-better metrics correctly
- No Vitest deprecation warnings for timeout syntax
- No ESM module warnings in benchmark runner
- CI pipeline includes infrastructure tests and install verification
- All existing tests continue to pass
</success_criteria>

<output>
After completion, create `.planning/phases/00-deployment-infrastructure/00-05-SUMMARY.md`
</output>
