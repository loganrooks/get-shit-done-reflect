---
phase: 25-backlog-system-core
plan: 02
type: execute
wave: 2
depends_on: [25-01]
files_modified:
  - get-shit-done/bin/gsd-tools.js
  - get-shit-done/bin/gsd-tools.test.js
autonomous: true

must_haves:
  truths:
    - "backlog group clusters items by theme (default) or by tags when --by tags specified"
    - "backlog promote sets status to planned and populates promoted_to with the target ID"
    - "backlog index generates index.md with a Markdown table of all items sorted by priority then date"
    - "backlog add --global creates items in ~/.gsd/backlog/items/ (via GSD_HOME)"
    - "backlog list --global reads items from the global backlog directory"
    - "backlog index auto-regenerates after add, update, and promote operations"
  artifacts:
    - path: "get-shit-done/bin/gsd-tools.js"
      provides: "cmdBacklogGroup, cmdBacklogPromote, cmdBacklogIndex functions and --global support"
      contains: "cmdBacklogGroup"
    - path: "get-shit-done/bin/gsd-tools.test.js"
      provides: "Tests for backlog group, promote, index commands and --global flag"
      contains: "backlog group"
  key_links:
    - from: "cmdBacklogGroup"
      to: "readBacklogItems"
      via: "reads all items then groups by field"
      pattern: "readBacklogItems\\("
    - from: "cmdBacklogPromote"
      to: "cmdBacklogUpdate"
      via: "reuses update logic to set status and promoted_to"
      pattern: "cmdBacklogUpdate\\(|status.*planned"
    - from: "cmdBacklogIndex"
      to: "resolveBacklogDir"
      via: "resolves items directory and writes index.md to parent"
      pattern: "resolveBacklogDir\\("
    - from: "cmdBacklogAdd"
      to: "cmdBacklogIndex"
      via: "auto-regenerates index after creating item"
      pattern: "cmdBacklogIndex\\("
---

<objective>
Build the remaining backlog commands (group, promote, index), add --global flag support for two-tier storage, and wire auto-regeneration of index.md after write operations.

Purpose: This completes the backlog CLI tooling. Group enables theme-based clustering for milestone planning. Promote enables transitioning ideas to planned work. Index provides a browsable overview. Global storage enables cross-project idea capture.

Output: Working backlog group/promote/index commands with tests, --global flag on add/list/stats/index, and auto-regeneration of index.md.

**Approach: TDD** -- write all tests first (Task 1), then implement to make them pass (Task 2).
</objective>

<execution_context>
@/Users/rookslog/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rookslog/.claude/get-shit-done/templates/summary-standard.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/25-backlog-system-core/25-RESEARCH.md
@.planning/phases/25-backlog-system-core/25-01-SUMMARY.md
@get-shit-done/bin/gsd-tools.js
@get-shit-done/bin/gsd-tools.test.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write failing tests for backlog group, promote, index and --global flag</name>
  <files>
    get-shit-done/bin/gsd-tools.test.js
  </files>
  <action>
**TDD RED phase:** Write all tests first. They WILL fail because `backlog group`, `backlog promote`, and `backlog index` do not exist yet. That is expected and correct.

Reuse the `createBacklogItem` helper from Plan 01's tests. Add new describe blocks after the Plan 01 test blocks.

**Tests for `backlog group` (3 tests):**

1. **groups items by theme (default)**: Create 3 items: 2 with theme "authentication" and 1 with theme "ux". Run `backlog group`, verify output has `groups` object with keys "authentication" (2 items) and "ux" (1 item).

2. **groups items by tags**: Create 2 items: one with tags [auth, api] and one with tags [auth, ui]. Run `backlog group --by tags`, verify output groups by tag name. "auth" should have 2 items, "api" should have 1, "ui" should have 1. Items can appear in multiple groups when they have multiple tags.

3. **defaults to theme when no --by specified**: Same as test 1 but don't pass `--by` argument. Verify `group_by` field in output is "theme".

**Tests for `backlog promote` (3 tests):**

4. **updates status to planned and sets promoted_to**: Create item, run `backlog promote <id> --to REQ-42`, read file, verify `status: planned` and `promoted_to: REQ-42`.

5. **sets status to planned without --to**: Create item, run `backlog promote <id>` (no --to), read file, verify `status: planned` and `promoted_to` remains null.

6. **fails for nonexistent item ID**: Run `backlog promote nonexistent-id`, verify command returns error.

**Tests for `backlog index` (2 tests):**

7. **generates index.md with table of all items**: Create 2 items (one HIGH, one LOW), run `backlog index`, verify `index.md` exists in `.planning/backlog/` (parent of items dir), contains a Markdown table with both items, sorted by priority (HIGH first).

8. **index sorts by priority then date**: Create 3 items: HIGH (2026-02-20), LOW (2026-02-22), HIGH (2026-02-22). Run `backlog index`, read index.md, verify order is HIGH-2026-02-22, HIGH-2026-02-20, LOW-2026-02-22 (HIGH before LOW, newer before older within same priority).

**Tests for `--global` flag (3 tests):**

For all --global tests, use the `GSD_HOME` environment variable to redirect global storage to a temp directory. The `runGsdTools` helper may need an `env` option -- check if it already supports one. If not, create a `runGsdToolsWithEnv` variant that accepts an `env` parameter passed to `execSync`.

9. **backlog add --global creates item in GSD_HOME/backlog/items/**: Set `GSD_HOME` to temp dir, run `backlog add --title "Global idea" --global`, verify file exists in `<GSD_HOME>/backlog/items/`.

10. **backlog list --global reads from global directory**: Set `GSD_HOME` to temp dir, create item file directly in `<GSD_HOME>/backlog/items/`, run `backlog list --global`, verify item returned.

11. **backlog index --global generates index in GSD_HOME/backlog/**: Set `GSD_HOME` to temp dir, create item file in global dir, run `backlog index --global`, verify `index.md` exists in `<GSD_HOME>/backlog/`.

**After writing all tests, run the test suite:** `node --test get-shit-done/bin/gsd-tools.test.js`. The 11 new tests MUST fail (the commands don't exist yet). All existing tests (including Plan 01's 17) MUST still pass.
  </action>
  <verify>
1. Run: `node --test get-shit-done/bin/gsd-tools.test.js 2>&1 | tail -10` -- 11 new tests fail, all existing tests (including Plan 01 tests) still pass
2. `grep -c 'backlog group\|backlog promote\|backlog index\|--global' get-shit-done/bin/gsd-tools.test.js` returns 10+
  </verify>
  <done>
11 tests written and confirmed failing: 3 for backlog group (by theme, by tags, default), 3 for backlog promote (with --to, without --to, nonexistent), 2 for backlog index (table generation, priority+date sort), 3 for --global flag (add, list, index). Existing test suite (including Plan 01 tests) still passes. TDD red phase complete.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement backlog group, promote, index + --global support + auto-regeneration to make all tests pass</name>
  <files>
    get-shit-done/bin/gsd-tools.js
  </files>
  <action>
**TDD GREEN phase:** Implement the minimum code to make all 11 tests pass.

**Part A: Add cmdBacklogGroup**

Add after existing backlog command functions:

```javascript
function cmdBacklogGroup(cwd, groupBy, isGlobal, raw) {
  const items = readBacklogItems(cwd, isGlobal);
  const groups = {};

  if (groupBy === 'tags') {
    for (const item of items) {
      const tags = Array.isArray(item.tags) ? item.tags : [];
      if (tags.length === 0) {
        const key = '(untagged)';
        if (!groups[key]) groups[key] = [];
        groups[key].push(item);
      } else {
        for (const tag of tags) {
          if (!groups[tag]) groups[tag] = [];
          groups[tag].push(item);
        }
      }
    }
  } else {
    // Default: group by theme
    for (const item of items) {
      const key = item.theme || '(no theme)';
      if (!groups[key]) groups[key] = [];
      groups[key].push(item);
    }
  }

  output({
    group_by: groupBy || 'theme',
    group_count: Object.keys(groups).length,
    total_items: items.length,
    groups,
  }, raw, `${Object.keys(groups).length} groups`);
}
```

**Part B: Add cmdBacklogPromote**

```javascript
function cmdBacklogPromote(cwd, itemId, target, raw) {
  if (!itemId) { error('item ID required for backlog promote'); }

  const itemsDir = resolveBacklogDir(cwd, false);
  let targetFile = null;
  let targetPath = null;

  try {
    const files = fs.readdirSync(itemsDir).filter(f => f.endsWith('.md'));
    for (const file of files) {
      const content = fs.readFileSync(path.join(itemsDir, file), 'utf-8');
      const fm = extractFrontmatter(content);
      if (fm.id === itemId) {
        targetFile = file;
        targetPath = path.join(itemsDir, file);
        break;
      }
    }
  } catch {}

  if (!targetPath) { error(`Backlog item not found: ${itemId}`); }

  const content = fs.readFileSync(targetPath, 'utf-8');
  const fm = extractFrontmatter(content);

  fm.status = 'planned';
  if (target) {
    fm.promoted_to = target;
  }
  fm.updated = new Date().toISOString();

  const bodyMatch = content.match(/^---\n[\s\S]+?\n---\n([\s\S]*)$/);
  const body = bodyMatch ? bodyMatch[1] : '\n\n## Description\n\n_No description provided._\n';
  const fmStr = reconstructFrontmatter(fm);
  const newContent = `---\n${fmStr}\n---\n${body}`;

  fs.writeFileSync(targetPath, newContent, 'utf-8');

  // Auto-regenerate index
  try { cmdBacklogIndex(cwd, false, true); } catch {}

  output({
    promoted: true,
    id: itemId,
    status: 'planned',
    promoted_to: target || null,
    file: targetFile,
  }, raw, itemId);
}
```

**Part C: Add cmdBacklogIndex**

```javascript
function cmdBacklogIndex(cwd, isGlobal, raw) {
  const itemsDir = resolveBacklogDir(cwd, isGlobal);
  const indexPath = path.join(path.dirname(itemsDir), 'index.md');

  let items = [];
  try {
    const files = fs.readdirSync(itemsDir).filter(f => f.endsWith('.md'));
    for (const file of files) {
      const content = fs.readFileSync(path.join(itemsDir, file), 'utf-8');
      const fm = extractFrontmatter(content);
      items.push({
        id: fm.id || file.replace('.md', ''),
        title: fm.title || 'Untitled',
        priority: fm.priority || 'MEDIUM',
        status: fm.status || 'captured',
        tags: Array.isArray(fm.tags) ? fm.tags.join(', ') : (fm.tags || ''),
        created: (fm.created || '').split('T')[0],
      });
    }
  } catch {}

  // Sort by priority (HIGH first), then date (newest first)
  const priorityOrder = { HIGH: 0, MEDIUM: 1, LOW: 2 };
  items.sort((a, b) =>
    (priorityOrder[a.priority] ?? 1) - (priorityOrder[b.priority] ?? 1)
    || b.created.localeCompare(a.created)
  );

  const generated = new Date().toISOString();
  let md = `# Backlog Index\n\n**Generated:** ${generated}\n**Total items:** ${items.length}\n\n`;
  md += `| ID | Title | Priority | Status | Tags | Date |\n`;
  md += `|----|-------|----------|--------|------|------|\n`;
  for (const item of items) {
    md += `| ${item.id} | ${item.title} | ${item.priority} | ${item.status} | ${item.tags} | ${item.created} |\n`;
  }

  // Ensure parent directory exists and write atomically
  fs.mkdirSync(path.dirname(indexPath), { recursive: true });
  const tmpPath = indexPath + '.tmp';
  fs.writeFileSync(tmpPath, md, 'utf-8');
  fs.renameSync(tmpPath, indexPath);

  output({ generated, total: items.length, path: indexPath }, raw, `Index rebuilt: ${items.length} items`);
}
```

**Part D: Wire group, promote, index into CLI router**

In the `case 'backlog':` switch block, add the remaining subcommand handlers:

```javascript
} else if (subcommand === 'group') {
  const byIdx = args.indexOf('--by');
  const globalFlag = args.includes('--global');
  cmdBacklogGroup(cwd, byIdx !== -1 ? args[byIdx + 1] : 'theme', globalFlag, raw);
} else if (subcommand === 'promote') {
  const itemId = args[2];
  const toIdx = args.indexOf('--to');
  cmdBacklogPromote(cwd, itemId, toIdx !== -1 ? args[toIdx + 1] : null, raw);
} else if (subcommand === 'index') {
  const globalFlag = args.includes('--global');
  cmdBacklogIndex(cwd, globalFlag, raw);
}
```

**Part E: Add auto-regeneration of index after add and update**

In `cmdBacklogAdd`, after the `fs.writeFileSync` that creates the item file and before the `output()` call, add:

```javascript
// Auto-regenerate index
try { cmdBacklogIndex(cwd, isGlobal, true); } catch {}
```

The `true` for the `raw` parameter suppresses output from the index command (we only want the add command's output). Note: since cmdBacklogIndex uses `output()` which writes to stdout, passing `raw` suppresses the JSON envelope. To avoid double-output, refactor slightly: extract the index generation logic into a separate `regenerateBacklogIndex(cwd, isGlobal)` function that does not call `output()`, then have `cmdBacklogIndex` call that function and add the `output()` wrapper. Both `cmdBacklogAdd` and `cmdBacklogPromote` call the silent `regenerateBacklogIndex()`.

Similarly, in `cmdBacklogUpdate`, add auto-regeneration after the write:

```javascript
// Auto-regenerate index
try { regenerateBacklogIndex(cwd, false); } catch {}
```

**Part F: Run tests -- all 11 must now pass**

Run the full test suite. All 11 new tests must pass. All existing tests (including Plan 01's 17) must still pass. If any test fails, fix the implementation (not the test) until green.
  </action>
  <verify>
1. Run `node --test get-shit-done/bin/gsd-tools.test.js` -- ALL tests pass (0 failures), including Plan 01's 17 + Plan 02's 11 = 28+ backlog tests
2. Run `grep -c 'cmdBacklogGroup\|cmdBacklogPromote\|cmdBacklogIndex\|regenerateBacklogIndex' get-shit-done/bin/gsd-tools.js` -- returns 4+ (function declarations)
3. Manual test: Create a backlog item then check index was auto-generated: `node gsd-tools.js backlog add --title "Test auto-index" --raw && cat .planning/backlog/index.md` -- index.md should exist with the item
4. Manual test: `node gsd-tools.js backlog group --raw` -- should return groups object
5. Verify no .tmp file: `ls .planning/backlog/index.md.tmp 2>/dev/null` -- should not exist
  </verify>
  <done>
TDD green phase complete. All 11 tests pass. backlog group clusters by theme (default) or tags (--by tags), with items appearing in multiple tag groups. backlog promote updates status to planned and sets promoted_to. backlog index generates sorted Markdown table. --global flag routes to GSD_HOME/backlog/ for add, list, and index. Index auto-regenerates after add, update, and promote. No regressions in Plan 01 tests or existing test suite.
  </done>
</task>

</tasks>

<verification>
1. Full test suite passes: `node --test get-shit-done/bin/gsd-tools.test.js` -- 0 failures, 28+ backlog tests pass
2. Group works: `node gsd-tools.js backlog group --raw` returns groups by theme
3. Promote works: `node gsd-tools.js backlog promote <id> --to REQ-01 --raw` returns promoted: true
4. Index generated: `cat .planning/backlog/index.md` shows Markdown table with priority-then-date sort
5. Global flag works: `GSD_HOME=/tmp/test-gsd node gsd-tools.js backlog add --title "Global" --global --raw` creates in /tmp/test-gsd/backlog/items/
</verification>

<success_criteria>
- TDD: Tests written BEFORE implementation, confirmed failing, then implementation makes them pass
- backlog group clusters by theme (default) and by tags (--by tags)
- backlog promote updates status to planned and optionally sets promoted_to
- backlog index generates sorted Markdown table (priority then date)
- --global flag works for add, list, stats, index commands (BLOG-02)
- Index auto-regenerates after add, update, promote operations (BLOG-07)
- 11+ tests pass for group, promote, index, and --global
- No regressions in Plan 01 tests or existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/25-backlog-system-core/25-02-SUMMARY.md`
</output>
