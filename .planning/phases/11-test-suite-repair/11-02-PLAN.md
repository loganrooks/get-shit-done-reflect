---
phase: 11-test-suite-repair
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - get-shit-done/bin/gsd-tools-fork.test.js
  - package.json
autonomous: true

must_haves:
  truths:
    - "Fork config fields (health_check, devops, gsd_reflect_version) round-trip through config-set and config-get without data loss"
    - "Nested fork config fields (health_check.frequency, devops.ci_provider) can be set and retrieved individually"
    - "All 75 existing upstream gsd-tools tests still pass after fork test file is added"
  artifacts:
    - path: "get-shit-done/bin/gsd-tools-fork.test.js"
      provides: "Fork-specific gsd-tools config field tests"
      contains: "config-set"
  key_links:
    - from: "get-shit-done/bin/gsd-tools-fork.test.js"
      to: "get-shit-done/bin/gsd-tools.js"
      via: "subprocess execution of config-set and config-get commands"
      pattern: "runGsdTools"
---

<objective>
Create fork-specific gsd-tools tests that validate custom config fields (health_check, devops, gsd_reflect_version) round-trip correctly through config-set/config-get commands. These tests cover fork extensions to the upstream config system that have zero test coverage today.

Purpose: The fork adds 3 custom config sections (health_check, devops, gsd_reflect_version) to upstream's config.json. Without round-trip tests, config commands could silently drop or corrupt these fork fields during set/get operations.
Output: New gsd-tools-fork.test.js file using node:test (matching upstream convention) with fork config field tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-test-suite-repair/11-RESEARCH.md

# Key source files
@get-shit-done/bin/gsd-tools.test.js
@get-shit-done/bin/gsd-tools.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create fork-specific gsd-tools config test file</name>
  <files>get-shit-done/bin/gsd-tools-fork.test.js</files>
  <action>
Create `get-shit-done/bin/gsd-tools-fork.test.js` using the node:test framework (matching upstream convention). This is a SEPARATE file from gsd-tools.test.js to maintain zero merge friction with upstream (per Phase 9 decision: "Separate fork-tools.js over modifying gsd-tools.js").

Follow the exact same test helper pattern from gsd-tools.test.js:
- Import `{ describe, test, beforeEach, afterEach }` from `node:test`
- Import `assert` from `node:assert/strict`
- Use `runGsdTools(args, cwd)` helper (copy the helper function -- it spawns `node gsd-tools.js {args}` in a subprocess)
- Use `createTempProject()` and cleanup pattern from gsd-tools.test.js (creates temp dir with `.planning/config.json` and git init)

Write these test cases in a describe block "config-set/config-get fork custom fields":

1. **"sets and gets health_check.frequency"** -- config-set health_check.frequency milestone-only, then config-get health_check.frequency, verify output is "milestone-only"
2. **"sets and gets health_check.stale_threshold_days"** -- config-set health_check.stale_threshold_days 7, verify via config-get (note: numeric values may parse as numbers)
3. **"sets and gets devops.ci_provider"** -- config-set devops.ci_provider github-actions, verify round-trip
4. **"sets and gets devops.commit_convention"** -- config-set devops.commit_convention conventional, verify round-trip
5. **"sets and gets gsd_reflect_version"** -- config-set gsd_reflect_version 1.13.0, verify it stays as string (contains dots, should not be parsed as number)
6. **"preserves existing config when setting fork fields"** -- Create config with upstream field (mode: "yolo"), set health_check.frequency, verify mode is still "yolo" in the file
7. **"sets nested devops.environments as JSON array"** -- If config-set supports it, set devops.environments to a value, verify structure. If not, test that the field can be set via direct JSON manipulation and is preserved by subsequent config-set calls on other fields.

For each test:
- Create a temp directory with git init and `.planning/config.json`
- Run config-set via runGsdTools()
- Verify via either config-get or reading config.json directly
- Clean up temp directory in afterEach

Read the existing gsd-tools.test.js to understand the exact createTempProject pattern and helper function signature before writing. The file is at `get-shit-done/bin/gsd-tools.test.js`.
  </action>
  <verify>Run `node --test get-shit-done/bin/gsd-tools-fork.test.js` -- all fork config tests pass</verify>
  <done>gsd-tools-fork.test.js exists with 7 test cases covering all fork custom config fields. Tests use node:test framework matching upstream convention. All tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: Add test:upstream:fork script and verify both upstream test suites pass</name>
  <files>package.json</files>
  <action>
Add a new npm script `test:upstream:fork` to package.json that runs the fork-specific gsd-tools tests:

```json
"test:upstream:fork": "node --test get-shit-done/bin/gsd-tools-fork.test.js"
```

Then run both upstream test suites to verify no regressions:
1. `npm run test:upstream` -- all 75 upstream tests pass
2. `npm run test:upstream:fork` -- all fork config tests pass

If any upstream tests fail, investigate whether the failure is pre-existing (unrelated to this plan's changes) or introduced by the new test file. The new file should have zero impact on existing tests since it's a separate file.

If any fork config tests fail, debug:
- Check if config-set handles nested keys (dot notation like health_check.frequency)
- Check if config-get returns the value in expected format (raw value vs JSON)
- Adjust assertions to match actual gsd-tools.js behavior
  </action>
  <verify>Run `npm run test:upstream` (75 tests pass) and `npm run test:upstream:fork` (7 tests pass)</verify>
  <done>Both upstream test suites pass. package.json has test:upstream:fork script. Fork config fields (health_check, devops, gsd_reflect_version) are validated through round-trip config-set/config-get tests.</done>
</task>

</tasks>

<verification>
1. `node --test get-shit-done/bin/gsd-tools-fork.test.js` passes all tests
2. `node --test get-shit-done/bin/gsd-tools.test.js` still passes all 75 tests (no regression)
3. Fork config tests cover health_check, devops, and gsd_reflect_version fields
4. Tests use node:test framework (not vitest) matching upstream convention
5. Test file is separate from upstream test file (zero merge friction)
</verification>

<success_criteria>
- Fork-specific gsd-tools tests exist and pass (TEST-02 fork extension)
- All 75 upstream gsd-tools tests still pass (TEST-02 baseline)
- Fork config fields round-trip through config-set/config-get without data loss
- Test file follows upstream conventions (node:test, subprocess execution)
</success_criteria>

<output>
After completion, create `.planning/phases/11-test-suite-repair/11-02-SUMMARY.md`
</output>
